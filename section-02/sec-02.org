#+AUTHOR:
#+TITLE:
#+OPTIONS:     toc:nil num:nil
#+LATEX_HEADER: \usepackage{mathrsfs}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{dcolumn}
#+LATEX_HEADER: \usepackage{subfigure}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.1,0.2,0.9}}}
#+LATEX: \renewcommand{\P}{{\bf P}}
#+LATEX: \newcommand{\ep}{{\bf e}^\prime}
#+LATEX: \newcommand{\e}{{\bf e}}
#+LATEX: \newcommand{\I}{{\bf I}}
#+LATEX: \newcommand{\W}{{\bf W}}
#+LATEX: \newcommand{\w}{{\bf w}}
#+LATEX: \newcommand{\X}{{\bf X}}
#+LATEX: \newcommand{\x}{{\bf x}}
#+LATEX: \newcommand{\Y}{{\bf Y}}
#+LATEX: \newcommand{\y}{{\bf y}}
#+LATEX: \newcommand{\Z}{{\bf Z}}
#+LATEX: \newcommand{\z}{{\bf z}}
#+LATEX: \newcommand{\M}{{\bf M}}
#+LATEX: \newcommand{\A}{{\bf A}}
#+LATEX: \newcommand{\Ap}{{\bf A}^{\prime}}
#+LATEX: \newcommand{\B}{{\bf B}}
#+LATEX: \newcommand{\Bp}{{\bf B}^{\prime}}
#+LATEX: \newcommand{\Xp}{{\bf X}^{\prime}}
#+LATEX: \newcommand{\Mp}{{\bf M}^{\prime}}
#+LATEX: \newcommand{\yp}{{\bf y}^{\prime}}
#+LATEX: \newcommand{\yh}{\hat{{\bf y}}}
#+LATEX: \newcommand{\yhp}{\hat{{\bf y}}^{\prime}}
#+LATEX: \newcommand{\In}{{\bf I}_n}
#+LATEX: \newcommand{\email}[1]{\textcolor{blue}{\texttt{#1}}}
#+LATEX: \newcommand{\id}[1]{{\bf I}_{#1}}
#+LATEX: \newcommand{\myheader}[1]{\textcolor{black}{\textbf{#1}}}
#+LATEX: \setlength{\parindent}{0in}
#+STARTUP: fninline

*Matrix operations in =R=* \hfill
*ARE212*: Section 02 \\ \hline \bigskip

This section continues where we left off last week, introducing you to increasingly complex matrix manipulation in =R=. Next week we will be working with real data again, so don't despair! \\

But first, as promised, some answers to questions from last week:
* Questions from last week's section
*Supplementary materials for each section*: Last week we had some trouble accessing the dataset I used in section. Sorry about that. In this and all future sections, supplementary materials will be posted before section in the section notes folder.

*Row names*: Dataframe rows also have names in =R=. The preferred function to get and set those names is =row.names()=, which is the row analogue of =names()=. Since there are 74 rows, I only show the first five, but you get the point.

#+BEGIN_SRC R :results output :exports none :session :tangle yes
require(foreign)
data <- read.csv("auto.csv", header=TRUE)
names(data) <- c("price", "mpg", "weight")
#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
row.names(data)[1:5]
row.names(data) <- 3:76
row.names(data)[1:5]
row.names(data)[1:2]  <- c("myrow1","myrow2")
row.names(data)[1:5]
#+END_SRC

#+RESULTS:
: [1] "1" "2" "3" "4" "5"
: [1] "3" "4" "5" "6" "7"
: [1] "myrow1" "myrow2" "5"      "6"      "7"

As you can see, you can set as many or as few of the row names as you like. Note that we have to be careful when rewriting an already existing vector in =R=. If the sizes don't match, it will throw an error. Try it! \\

*Row means*: Here's how to calculate the mean of a row in R. This example isn't very meaningful, since we're averaging =price=, =mpg=, and =weight=, but it works as a proof of concept. 
#+BEGIN_SRC R :results output :exports both :session :tangle yes
data$price[2] = NA
weirdmeans1 <- data.frame(Means=rowMeans(data))
weirdmeans2 <- data.frame(Means=rowMeans(data, na.rm=TRUE))
cbind(head(weirdmeans1),head(weirdmeans2))
#+END_SRC

#+RESULTS:
:           Means    Means
: myrow1 2350.333 2350.333
: myrow2       NA 1683.500
: 5      2153.667 2153.667
: 6      2695.333 2695.333
: 7      3974.000 3974.000
: 8      3158.667 3158.667

There are a couple wrinkles in here. First, to make it more interesting, I set one of prices equal to =NA=, which is =R=-speak for "not available". The first time we take =rowMeans=, =R= basically tells us that it can't take the mean of a set of numbers when one of them is not available[fn:: In high school, I had a friend named Jared who got his license a full year before the rest of us. Apparently he was told that if he had more than one person in the car he could get arrested, so if we ever wanted to get anywhere he had to shuttle us. =R= is kind of acting like Jared here.]. But by passing the optional argument =na.rm=TRUE= we can tell =R= to recklessly take the mean of the remaining numbers. The second wrinkle is less interesting but also useful --- I just used =cbind()= to bind the two means columns together in a data frame for easy of display.\\ 

*Double Y Axes*: 

Overlaying two variables on the same axis is a convenient way to display the two relationships at the same time. In this case, let's say we want to visually compare how price and weight change with miles per gallon. We can do this by telling =R= to draw a second scatterplot directly on top of the first one. 

#+begin_src R :results output graphics :file inserts/graph1.png :width 500 :height 300 :session :tangle yes :exports both
par(mar=c(5.1,4.1,4.1,5.1)) # just so we can fit the label for the second y axis
plot(data$mpg,data$price,col="red",ylab="price",xlab="mpg")
par(new=TRUE)
plot(data$mpg,data$weight,col="blue",xaxt="n",yaxt="n",xlab="",ylab="")
axis(4)
mtext("weight",side=4,line=3)
#+END_SRC

#+RESULTS:
[[file:inserts/graph1.png]]

There are a lot of new commands here[fn:: Credit to Professor Rob J Hyndman for this code. Original available here: http://robjhyndman.com/hyndsight/r-graph-with-two-y-axes/.]. =par()= lets us pre-set parameters for what we're about to graph. First, we set =mar= to increase the size of the right-hand side margin in order to fit the label for the second axis. Second, we set =new=TRUE=, which allows us to draw our second scatterplot on the same plotting device[fn:: No, the boolean choice here doesn't make sense to me either.].
\newpage

* Creating and testing matrices

The lingua franca of this course is matrix algebra, so we will start by introducing some of the more common commands for working with matrices in =R=. \\

There are a variety of data objects in =R=, including numbers, vectors, matrices, strings, and dataframes.  We will mainly be working with vectors and matrices, which are quick to create and manipulate in =R=. The =matrix= function will create a matrix, according to the supplied arguments. \\

#+BEGIN_SRC R :results output :exports both :session :tangle yes
(A <- matrix(1:6, ncol=2))
#+END_SRC

#+RESULTS:
:      [,1] [,2]
: [1,]    1    4
: [2,]    2    5
: [3,]    3    6

#+BEGIN_SRC R :results output :exports both :session :tangle yes
(B <- matrix(1:6, ncol=3, byrow=TRUE))
#+END_SRC

#+RESULTS:
:      [,1] [,2] [,3]
: [1,]    1    2    3
: [2,]    4    5    6

For convenience, we use =->= to assign the matrices to the variables =A= and =B= for use in subsequent manipulations. The $=$ operator also assigns values, with a slightly different behavior[fn:: It is also common practice to use the === operator for function arguments.] . The =ncol= option specifies the number of columns for the output matrix; and the default behavior of =matrix= is to cycle through by column.  To cycle through by rows we set the optional argument =byrow=TRUE=. \\

Suppose we wanted to check to see if the first matrix was equal to the transpose of the second. This is clearly the case --- we can see that it is. But when we're working with larger matrices it will be convenient to have a way to do this programmatically. The ==== comparison operator will yield =TRUE= or =FALSE=:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
A == t(B)
#+END_SRC

#+RESULTS:
:      [,1] [,2]
: [1,] TRUE TRUE
: [2,] TRUE TRUE
: [3,] TRUE TRUE

Note that =t()= will return the transpose of the supplied matrix.  Each element is checked individually, and each is identical in matrix $\A$ and $\Bp$.  To check the truthiness of the statement that all elements are identical, we need only to employ the =all= function:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
all(A == t(B))
#+END_SRC

#+RESULTS:
: [1] TRUE

Keeping track of your matrix dimensions is a Good Idea\texttrademark. That's where the =dim()= command comes in handy:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
dim(A)
dim(B)
#+END_SRC

#+RESULTS:
: [1] 3 2
: [1] 2 3

With the dimensions of our matrices in mind, we'll move on to matrix operations.

* Matrix operations

Matrix muliplication in =R= is bound to =%*%=, whereas scalar multiplication is bound to =*=.  Consider the product $\B\A$:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
B %*% A
#+END_SRC

#+RESULTS:
:      [,1] [,2]
: [1,]   14   32
: [2,]   32   77

The dimensions have to line up properly for matrix multiplication to be appropriately applied, otherwise =R= returns an error, as is the case with the product $\B\Ap$:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
B %*% t(A)
#+END_SRC

#+RESULTS:
: Error in B %*% t(A) : non-conformable arguments

If scalar multiplication is applied to matrices of exactly the same dimensions, then the result is element-wise multiplication.  This type of operation is sometimes called the Hadamard product, denoted $\B \circ \Ap$:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
B * t(A)
#+END_SRC

#+RESULTS:
:      [,1] [,2] [,3]
: [1,]    1    4    9
: [2,]   16   25   36

Suppose we want to scale all elements by a factor of two. This is similar, we just multiply the matrix by a scalar using the regular =*= operator.

#+BEGIN_SRC R :results output :exports both :session :tangle yes
A * 2
#+END_SRC

#+RESULTS:
:      [,1] [,2]
: [1,]    2    8
: [2,]    4   10
: [3,]    6   12

Consider a more complicated operation, whereby each column of a matrix is multiplied element-wise by another, fixed column. Here, each column of a particular matrix is multiplied in-place by a fixed column of residuals.  Let $\e$ be a
vector defined as an increasing sequence of length three:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
e <- matrix(1:3)
#+END_SRC

#+results:

Note first that the default sequence in =R= is a column vector, and not a row vector.  We would like to =apply= a function to each column of $\A$, specifically a function that multiplies each column in-place by $\e$.  We must supply a 2 to ensure that the function is applied to the second dimension (columns) of $\A$:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
apply(A, 2, function(x) {x * e})
#+END_SRC

#+RESULTS:
:      [,1] [,2]
: [1,]    1    4
: [2,]    4   10
: [3,]    9   18

The function that is applied is anonymous, but it could also be bound to a variable -- just as a matrix is bound to a variable:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
whoop <- function(x) {x * e}
apply(A, 2, whoop)
#+END_SRC

#+RESULTS:
:      [,1] [,2]
: [1,]    1    4
: [2,]    4   10
: [3,]    9   18

We will often need to define an identity matrix of dimension $n$, or $\In$.  This is quick using =diag=:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
I <- diag(5)
#+END_SRC

#+RESULTS:

As you know, $\In = \In^{-1}$. We can verify this with the =solve()= command, which will return the inverse of a square matrix[fn:: Note that we can't use =solve()= on $\A$ or $\B$ since neither are square.].

#+BEGIN_SRC R :results output :exports both :session :tangle yes
all(solve(I) == I)
#+END_SRC

#+RESULTS:
: Error in as.vector(x, mode) : 
:   cannot coerce type 'closure' to vector of type 'any'

There are many ways to calculate the trace of $\I_5$.  One method has been bundled into a function, called =tr()=, that is included in a package called =psych= which is not included in the base distribution of =R=.  We will need to grab and call the library to have access to the function, installing it with the command =install.packages("psych")=.  For this, you'll need an internet connection.

#+BEGIN_SRC R :results output :exports both :session :tangle yes
library(psych)
tr(I)
#+END_SRC

#+RESULTS:
: [1] 5

We can get a list of all the object currently available in memory with the =ls()= function, which is useful as the assignments begin to accumulate:

#+BEGIN_SRC R :results output :exports both :session :tangle yes
ls()
#+END_SRC

#+results:
: [1] "A"           "B"           "data"        "e"           "I"          
: [6] "weirdmeans1" "weirdmeans2" "whoop"

Note that the objects we did not explicitly assign, such the transpose of $\B$, =t(B)=, or the trace of \I, =tr(I)=, are created on the fly and not stored in memory. \\

When paired with the =rm()= function, we can use =ls()= to delete all of the objects in memory. This is similar to the command =clear= in Stata.

#+BEGIN_SRC R :results output :exports both :session :tangle yes
  rm(list = ls())
#+END_SRC

#+RESULTS:

What's going on here? =list= is actually the name of an argument built in to the =rm()= command. The default behavior of =rm= is to accept character strings; we could have alternatively specified =rm("A","B","data","e","I","weirdmeans1","weirdmeans2","whoop")= and the outcome would have been the same. But by passing it a list of all of the objects in memory, we are telling =rm()= to clear everything, not just the variables we name. \\

Next week we will leave the training wheels behind and dig into an example with real data. Now that we have all of the tools, our new best friend $(X'X)^{-1}X'y$ may even make an appearance. Hopefully you all have started work on the first problem set and are starting to feel at least somewhat comfortable in =R=. 

* Linear algebra puzzles

1. Define vectors $\x = [1 \hspace{6pt} 2 \hspace{6pt} 3]'$, $\y = [2 \hspace{6pt} 3 \hspace{6pt} 4]'$, and $\z = [3 \hspace{6pt} 5 \hspace{6pt} 7]$. Define $\W = [\x \hspace{6pt} \y \hspace{6pt} \z]$.  Calculate $\W^{-1}$.  If you cannot take the inverse, explain why not and adjust $\W$ so that you /can/ take the inverse. /Hint/: the =solve()= function will return the inverse of the supplied matrices.

2. Show, somehow, that $(\Xp)^{-1} = (\X^{-1})^{\prime}$.

3. Generate a $3 \times 3$ matrix $\X$, where each element is drawn from a standard normal distribution.  Let $\A = \I_3 - \frac{1}{3}\B$ be a demeaning matrix, with $\i$ a $3 \times 3$ matrix of ones.  First show that $\A$ is idempotent and symmetric. Next show that each row of the matrix $\X\A$ is the deviation of each row in $\X$ from its mean.  Finally, show that $(\X\A)(\X\A)^{\prime} = \X\A\Xp$, first through algebra and then =R= code.

4. Demonstrate from random matrices that $(\X\Y\Z)^{-1} = \Z^{-1}\Y^{-1}\X^{-1}$.

5. Let $\X$ and $\Y$ be square $20 \times 20$ matrices.  Show that $tr(\X + \Y) = tr(\X) + tr(\Y)$.

6. Generate a diagonal matrix $\X$, where each element on the diagnonal is drawn from $U[10,20]$. Now generate a matrix $\B$ s.t. $\X = \B\Bp$. /Hint/: There is a method in =R= that makes this easy. Does the fact that you can generate $\B$ tell you anything about $\X$?

7. Demonstrate that for any scalar $c$ and any square matrix $\X$ of dimension $n$ that $\det(c\X) = c^n \det(\X)$.

8. Demonstrate that for an $m \times m$ matrix $\A$ and a $p \times p$ matrix $\B$ that $\det(\A \otimes \B) = \det(\A)^p \det(\B)^m$. /Hint/: Note that $\otimes$ indicates the Kronecker product\footnote{The Kronecker product is a useful mathemagical tool for econometricians, allowing us to more easily describe block-diagonal matricees for use in panel data settings. I wouldn't lose sleep over it, though.}.  Google the appropriate =R= function.
